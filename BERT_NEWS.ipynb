{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: flask in /usr/local/lib/python3.8/dist-packages (from -r ./Poc/requirements.txt (line 1)) (2.0.3)\n",
      "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.8/dist-packages (from -r ./Poc/requirements.txt (line 2)) (2.2.0)\n",
      "Requirement already satisfied: numpy==1.19.5 in /usr/local/lib/python3.8/dist-packages (from -r ./Poc/requirements.txt (line 3)) (1.19.5)\n",
      "Requirement already satisfied: pdfminer.six==20201018 in /usr/local/lib/python3.8/dist-packages (from -r ./Poc/requirements.txt (line 4)) (20201018)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (from -r ./Poc/requirements.txt (line 5)) (4.17.0)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.8/dist-packages (from -r ./Poc/requirements.txt (line 6)) (1.18.4)\n",
      "Collecting seqeval\n",
      "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
      "\u001b[K     |████████████████████████████████| 43 kB 1.5 MB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.8/dist-packages (from flask->-r ./Poc/requirements.txt (line 1)) (3.0.3)\n",
      "Requirement already satisfied: Werkzeug>=2.0 in /usr/local/lib/python3.8/dist-packages (from flask->-r ./Poc/requirements.txt (line 1)) (2.0.2)\n",
      "Requirement already satisfied: click>=7.1.2 in /usr/local/lib/python3.8/dist-packages (from flask->-r ./Poc/requirements.txt (line 1)) (8.0.3)\n",
      "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.8/dist-packages (from flask->-r ./Poc/requirements.txt (line 1)) (2.1.1)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.8/dist-packages (from sentence-transformers->-r ./Poc/requirements.txt (line 2)) (3.7)\n",
      "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from sentence-transformers->-r ./Poc/requirements.txt (line 2)) (1.8.2+cu111)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from sentence-transformers->-r ./Poc/requirements.txt (line 2)) (4.63.0)\n",
      "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.8/dist-packages (from sentence-transformers->-r ./Poc/requirements.txt (line 2)) (0.4.0)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.8/dist-packages (from sentence-transformers->-r ./Poc/requirements.txt (line 2)) (0.9.2+cu111)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from sentence-transformers->-r ./Poc/requirements.txt (line 2)) (1.8.0)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from sentence-transformers->-r ./Poc/requirements.txt (line 2)) (1.0.2)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.8/dist-packages (from sentence-transformers->-r ./Poc/requirements.txt (line 2)) (0.1.96)\n",
      "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.8/dist-packages (from pdfminer.six==20201018->-r ./Poc/requirements.txt (line 4)) (2.4.0)\n",
      "Requirement already satisfied: cryptography in /usr/local/lib/python3.8/dist-packages (from pdfminer.six==20201018->-r ./Poc/requirements.txt (line 4)) (36.0.1)\n",
      "Requirement already satisfied: chardet; python_version > \"3.0\" in /usr/lib/python3/dist-packages (from pdfminer.six==20201018->-r ./Poc/requirements.txt (line 4)) (3.0.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers->-r ./Poc/requirements.txt (line 5)) (6.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers->-r ./Poc/requirements.txt (line 5)) (2.27.1)\n",
      "Requirement already satisfied: filelock in /usr/lib/python3/dist-packages (from transformers->-r ./Poc/requirements.txt (line 5)) (3.0.12)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers->-r ./Poc/requirements.txt (line 5)) (2022.3.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers->-r ./Poc/requirements.txt (line 5)) (21.3)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers->-r ./Poc/requirements.txt (line 5)) (0.11.6)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.8/dist-packages (from transformers->-r ./Poc/requirements.txt (line 5)) (0.0.47)\n",
      "Requirement already satisfied: pyarrow!=4.0.0,>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets->-r ./Poc/requirements.txt (line 6)) (7.0.0)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.8/dist-packages (from datasets->-r ./Poc/requirements.txt (line 6)) (2022.2.0)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.8/dist-packages (from datasets->-r ./Poc/requirements.txt (line 6)) (3.0.0)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.8/dist-packages (from datasets->-r ./Poc/requirements.txt (line 6)) (0.3.4)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.8/dist-packages (from datasets->-r ./Poc/requirements.txt (line 6)) (0.70.12.2)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets->-r ./Poc/requirements.txt (line 6)) (3.8.1)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from datasets->-r ./Poc/requirements.txt (line 6)) (1.4.0)\n",
      "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.8/dist-packages (from datasets->-r ./Poc/requirements.txt (line 6)) (0.18.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/dist-packages (from Jinja2>=3.0->flask->-r ./Poc/requirements.txt (line 1)) (2.0.1)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk->sentence-transformers->-r ./Poc/requirements.txt (line 2)) (1.1.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.6.0->sentence-transformers->-r ./Poc/requirements.txt (line 2)) (4.0.1)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.8/dist-packages (from torchvision->sentence-transformers->-r ./Poc/requirements.txt (line 2)) (9.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->sentence-transformers->-r ./Poc/requirements.txt (line 2)) (3.1.0)\n",
      "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.8/dist-packages (from cryptography->pdfminer.six==20201018->-r ./Poc/requirements.txt (line 4)) (1.15.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0; python_version >= \"3\" in /usr/local/lib/python3.8/dist-packages (from requests->transformers->-r ./Poc/requirements.txt (line 5)) (2.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers->-r ./Poc/requirements.txt (line 5)) (1.26.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->transformers->-r ./Poc/requirements.txt (line 5)) (2019.11.28)\n",
      "Requirement already satisfied: idna<4,>=2.5; python_version >= \"3\" in /usr/lib/python3/dist-packages (from requests->transformers->-r ./Poc/requirements.txt (line 5)) (2.8)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers->-r ./Poc/requirements.txt (line 5)) (3.0.7)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from sacremoses->transformers->-r ./Poc/requirements.txt (line 5)) (1.14.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets->-r ./Poc/requirements.txt (line 6)) (1.2.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets->-r ./Poc/requirements.txt (line 6)) (4.0.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets->-r ./Poc/requirements.txt (line 6)) (21.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets->-r ./Poc/requirements.txt (line 6)) (6.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets->-r ./Poc/requirements.txt (line 6)) (1.7.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets->-r ./Poc/requirements.txt (line 6)) (1.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets->-r ./Poc/requirements.txt (line 6)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets->-r ./Poc/requirements.txt (line 6)) (2021.3)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi>=1.12->cryptography->pdfminer.six==20201018->-r ./Poc/requirements.txt (line 4)) (2.21)\n",
      "Building wheels for collected packages: seqeval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Building wheel for seqeval (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16182 sha256=b874093b3328b15791ec0216ba8b88738842ebe5a36ccbfeffe0fbe5c2f98240\n",
      "  Stored in directory: /root/.cache/pip/wheels/ad/5c/ba/05fa33fa5855777b7d686e843ec07452f22a66a138e290e732\n",
      "Successfully built seqeval\n",
      "Installing collected packages: seqeval\n",
      "Successfully installed seqeval-1.2.2\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -r ./Poc/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizerFast, BertForPreTraining,BertForTokenClassification ,Trainer, TrainingArguments\n",
    "import os\n",
    "import torch \n",
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from array import array\n",
    "import numpy as np\n",
    "def loadData():\n",
    "    list_subfolders_with_paths = [f.path for f in os.scandir(\"./annotation3/\") if f.is_dir()]\n",
    "    data = {\"texts\": [],\"labels\":[]}\n",
    "    for i in list_subfolders_with_paths:\n",
    "    #print(\"new File\")\n",
    "        texts=[]\n",
    "        labels=[]\n",
    "        with open(f\"{i}/admin.conll\",\"r\", encoding=\"utf-8-sig\") as file: \n",
    "            for j in  file.readlines():\n",
    "                if(j.strip() == \"\"):\n",
    "                    continue\n",
    "                sp = j.split(\" \")\n",
    "                if(\"null\" in sp[1].rstrip(\"\\n\")):\n",
    "                    print(i)\n",
    "                texts.append(sp[0])\n",
    "                labels.append(sp[1].rstrip(\"\\n\"))\n",
    "                #print(f\"Text: {sp[0]}\")\n",
    "                #print(f\"Label: {sp[1]}\")\n",
    "            data[\"texts\"].append((texts))\n",
    "            data[\"labels\"].append(( labels))\n",
    "    \n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from array import array\n",
    "import numpy as np\n",
    "def loadData():\n",
    "    list_subfolders_with_paths = [f.path for f in os.scandir(\"./annotation3/\") if f.is_dir()]\n",
    "    data = {\"texts\": [],\"labels\":[]}\n",
    "    for i in list_subfolders_with_paths:\n",
    "    #print(\"new File\")\n",
    "        texts=[]\n",
    "        labels=[]\n",
    "        with open(f\"{i}/admin.conll\",\"r\", encoding=\"utf-8-sig\") as file: \n",
    "            for j in  file.readlines():\n",
    "                if(j.strip() == \"\"):\n",
    "                    if( \"SENTENCE_END\" in labels[-1] ):\n",
    "                        data[\"texts\"].append((texts))\n",
    "                        data[\"labels\"].append(( labels))\n",
    "                        texts=[]\n",
    "                        labels=[]\n",
    "                    continue\n",
    "                sp = j.split(\" \")\n",
    "                if(\"null\" in sp[1].rstrip(\"\\n\")):\n",
    "                    print(i)\n",
    "                texts.append(sp[0])\n",
    "                labels.append(sp[1].rstrip(\"\\n\"))\n",
    "                #print(f\"Text: {sp[0]}\")\n",
    "                #print(f\"Label: {sp[1]}\")\n",
    "            data[\"texts\"].append((texts))\n",
    "            data[\"labels\"].append(( labels))\n",
    "    \n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset , ClassLabel ,Features ,Sequence ,Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata = loadData()\n",
    "texts = traindata[\"texts\"]\n",
    "tags = traindata[\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PERSON_FIRSTNAME': 13.1,\n",
       " 'PERSON_LASTNAME': 14.08,\n",
       " 'PERSON_AGE': 6.64,\n",
       " 'SENTENCE_END': 43.22,\n",
       " 'LOCATION_CITY': 7.2,\n",
       " 'ORGANIZATION': 6.64,\n",
       " 'LOCATION_COUNTRY': 0.94,\n",
       " 'LOCATION_STREET': 1.5,\n",
       " 'LOCATION_ASSOSIATION': 1.96,\n",
       " 'LOCATION': 3.46,\n",
       " 'TELE_NUMMER': 1.26}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "x = [i[2:] if(len(i) > 1) else i for i in list(sum(tags, []))]\n",
    "di = dict(Counter(x))\n",
    "\n",
    "z = {}\n",
    "\n",
    "for i in di.keys():\n",
    "    if i == \"O\":\n",
    "        continue\n",
    "    z[i] = round ((di[i]/(len(x)-di[\"O\"]))*100,2)\n",
    "    \n",
    "\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_tags = set(tag for doc in tags for tag in doc)\n",
    "tag2id = {tag: id for id, tag in enumerate(unique_tags)}\n",
    "id2tag = {id: tag for tag, id in tag2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-TELE_NUMMER',\n",
       " 'I-ORGANIZATION',\n",
       " 'B-LOCATION_COUNTRY',\n",
       " 'B-ORGANIZATION',\n",
       " 'I-LOCATION_ASSOSIATION',\n",
       " 'I-PERSON_FIRSTNAME',\n",
       " 'B-LOCATION_STREET',\n",
       " 'B-PERSON_AGE',\n",
       " 'I-TELE_NUMMER',\n",
       " 'O',\n",
       " 'I-SENTENCE_END',\n",
       " 'I-LOCATION_STREET',\n",
       " 'I-LOCATION',\n",
       " 'B-LOCATION_ASSOSIATION',\n",
       " 'B-LOCATION',\n",
       " 'B-PERSON_FIRSTNAME',\n",
       " 'B-PERSON_LASTNAME',\n",
       " 'B-LOCATION_CITY',\n",
       " 'B-SENTENCE_END',\n",
       " 'I-PERSON_AGE',\n",
       " 'I-LOCATION_CITY']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(unique_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.from_dict(loadData(),features=Features( {\"texts\": Sequence(Value(\"string\")),'labels':Sequence(ClassLabel(names=list(unique_tags),num_classes =len(unique_tags)))}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.train_test_split(test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': 'B-TELE_NUMMER',\n",
       " '1': 'I-ORGANIZATION',\n",
       " '2': 'B-LOCATION_COUNTRY',\n",
       " '3': 'B-ORGANIZATION',\n",
       " '4': 'I-LOCATION_ASSOSIATION',\n",
       " '5': 'I-PERSON_FIRSTNAME',\n",
       " '6': 'B-LOCATION_STREET',\n",
       " '7': 'B-PERSON_AGE',\n",
       " '8': 'I-TELE_NUMMER',\n",
       " '9': 'O',\n",
       " '10': 'I-SENTENCE_END',\n",
       " '11': 'I-LOCATION_STREET',\n",
       " '12': 'I-LOCATION',\n",
       " '13': 'B-LOCATION_ASSOSIATION',\n",
       " '14': 'B-LOCATION',\n",
       " '15': 'B-PERSON_FIRSTNAME',\n",
       " '16': 'B-PERSON_LASTNAME',\n",
       " '17': 'B-LOCATION_CITY',\n",
       " '18': 'B-SENTENCE_END',\n",
       " '19': 'I-PERSON_AGE',\n",
       " '20': 'I-LOCATION_CITY'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{str(v): k for k, v in (dataset[\"train\"].features[\"labels\"].feature)._str2int.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'texts': ['SAMUEL',\n",
       "  'YEBOAH',\n",
       "  'STARB',\n",
       "  '1991',\n",
       "  'BEI',\n",
       "  'BRANDANSCHLAG',\n",
       "  'Plakate',\n",
       "  'erinnern',\n",
       "  'an',\n",
       "  'ermordeten',\n",
       "  'Flüchtling',\n",
       "  'Ursula',\n",
       "  'Quack',\n",
       "  'vom',\n",
       "  'Flüchtlingsrat',\n",
       "  'und',\n",
       "  'Roland',\n",
       "  'Röder',\n",
       "  'von',\n",
       "  'der',\n",
       "  'Aktion3',\n",
       "  '.',\n",
       "  'Welt',\n",
       "  'Saar',\n",
       "  'beim',\n",
       "  'Anbringen',\n",
       "  'des',\n",
       "  'ersten',\n",
       "  'Plakats',\n",
       "  'Foto',\n",
       "  ':',\n",
       "  'Dirk',\n",
       "  'Guldner',\n",
       "  '-',\n",
       "  'guldner.de',\n",
       "  '13.08.2021',\n",
       "  '-',\n",
       "  '19',\n",
       "  ':',\n",
       "  '38',\n",
       "  'Uhr',\n",
       "  'Saarlouis',\n",
       "  '–',\n",
       "  'Gigantische',\n",
       "  'Plakate',\n",
       "  'gegen',\n",
       "  'das',\n",
       "  'Vergessen',\n",
       "  '!',\n",
       "  'In',\n",
       "  'der',\n",
       "  'Nacht',\n",
       "  'zum',\n",
       "  '19',\n",
       "  '.',\n",
       "  'September',\n",
       "  '1991',\n",
       "  'verbrannte',\n",
       "  'Samuel',\n",
       "  'Yeboah',\n",
       "  '(',\n",
       "  '†',\n",
       "  '27',\n",
       "  ')',\n",
       "  'bei',\n",
       "  'einem',\n",
       "  'Anschlag',\n",
       "  'in',\n",
       "  'Fraulautern',\n",
       "  '.',\n",
       "  'Seit',\n",
       "  'letztem',\n",
       "  'Jahr',\n",
       "  'ermittelt',\n",
       "  'die',\n",
       "  'Bundesanwaltschaft',\n",
       "  'wegen',\n",
       "  'Mordes',\n",
       "  ',',\n",
       "  'geht',\n",
       "  'von',\n",
       "  'einem',\n",
       "  'rechtsextremen',\n",
       "  'Motiv',\n",
       "  'aus',\n",
       "  '(',\n",
       "  'BILD',\n",
       "  'berichtete',\n",
       "  ')',\n",
       "  '.',\n",
       "  'Samuel',\n",
       "  'Yeboah',\n",
       "  '(',\n",
       "  '†',\n",
       "  '27',\n",
       "  ')',\n",
       "  'Foto',\n",
       "  ':',\n",
       "  'Quelle',\n",
       "  ':',\n",
       "  'Landespolizeipräsidium',\n",
       "  'Saarland',\n",
       "  'Jetzt',\n",
       "  'soll',\n",
       "  'eine',\n",
       "  'Plakat-Aktion',\n",
       "  'an',\n",
       "  'den',\n",
       "  'ghanaischen',\n",
       "  'Flüchtling',\n",
       "  'erinnern',\n",
       "  '.',\n",
       "  'Insgesamt',\n",
       "  '30',\n",
       "  'großformatige',\n",
       "  'Poster',\n",
       "  'wollen',\n",
       "  'die',\n",
       "  'Aktion',\n",
       "  '3',\n",
       "  '.',\n",
       "  'Welt',\n",
       "  'Saar',\n",
       "  'e.V',\n",
       "  '.',\n",
       "  'und',\n",
       "  'der',\n",
       "  'Saarländische',\n",
       "  'Flüchtlingsrat',\n",
       "  'in',\n",
       "  'den',\n",
       "  'nächsten',\n",
       "  'Tagen',\n",
       "  'in',\n",
       "  'Saarlouis',\n",
       "  ',',\n",
       "  'Saarbrücken',\n",
       "  ',',\n",
       "  'Dillingen',\n",
       "  'und',\n",
       "  'Ensdorf',\n",
       "  'aufhängen',\n",
       "  '.',\n",
       "  'Ziel',\n",
       "  ':',\n",
       "  'die',\n",
       "  'Erinnerung',\n",
       "  'an',\n",
       "  'Yeboah',\n",
       "  'wachhalten',\n",
       "  ',',\n",
       "  'Rassismus',\n",
       "  'konsequent',\n",
       "  'bekämpfen',\n",
       "  'und',\n",
       "  'sich',\n",
       "  'für',\n",
       "  'eine',\n",
       "  'offene',\n",
       "  'und',\n",
       "  'freie',\n",
       "  'Gesellschaft',\n",
       "  'einsetzen',\n",
       "  '.',\n",
       "  'Das',\n",
       "  'erste',\n",
       "  'Plakat',\n",
       "  'wurde',\n",
       "  'gestern',\n",
       "  'in',\n",
       "  'der',\n",
       "  'Nähe',\n",
       "  'des',\n",
       "  'Saarlouiser',\n",
       "  'Hauptbahnhofs',\n",
       "  'angebracht',\n",
       "  '.'],\n",
       " 'labels': [15,\n",
       "  16,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  15,\n",
       "  16,\n",
       "  9,\n",
       "  3,\n",
       "  9,\n",
       "  15,\n",
       "  16,\n",
       "  9,\n",
       "  9,\n",
       "  3,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  17,\n",
       "  18,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  18,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  15,\n",
       "  16,\n",
       "  9,\n",
       "  9,\n",
       "  7,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  17,\n",
       "  18,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  3,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  18,\n",
       "  15,\n",
       "  16,\n",
       "  9,\n",
       "  9,\n",
       "  7,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  3,\n",
       "  1,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  18,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  3,\n",
       "  1,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  17,\n",
       "  9,\n",
       "  17,\n",
       "  9,\n",
       "  17,\n",
       "  9,\n",
       "  17,\n",
       "  9,\n",
       "  18,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  16,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  18,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  14,\n",
       "  12,\n",
       "  9,\n",
       "  18]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = dataset[\"train\"].features[f\"labels\"].feature.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d7e9b6234ad47ed8e4510e5914d82be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/83.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6caa3f91c8294d2689a1226e7da4979e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/234k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42ead1f5edc44cd7a3f5a30528868319",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cd3fbfd44594d71ac1b3c36e0df4a2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.25G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at deepset/gbert-large were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at deepset/gbert-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#Load Model and Tokenizer\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = BertTokenizerFast.from_pretrained('deepset/gbert-large')\n",
    "model = BertForTokenClassification.from_pretrained('deepset/gbert-large', num_labels=len(label_names) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.label2id =  (dataset[\"train\"].features[\"labels\"].feature)._str2int \n",
    "model.config.id2label =  {str(v): k for k, v in (dataset[\"train\"].features[\"labels\"].feature)._str2int.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    #print(examples.keys())\n",
    "    tokenized_inputs = tokenizer(examples[\"texts\"],max_length= 1024, truncation=True, is_split_into_words=True) # set max length 1024\n",
    "\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[\"labels\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)  # Map tokens to their respective word.\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:  # Set the special tokens to -100.\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:  # Only label the first token of a given word.\n",
    "                label_ids.append(label[word_idx])\n",
    "            else:\n",
    "                label_ids.append(-100)\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    \n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e40c4ae0b6984b3fa38c13e19413140d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "320d253791674ad588e8e12015135b83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_datasets = dataset.map(tokenize_and_align_labels, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['texts', 'labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 39\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['texts', 'labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 10\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(examples):\n",
    "    dic ={\"input_ids\":[],\"token_type_ids\":[],\"attention_mask\":[],\"labels\":[]}\n",
    "    for j in examples:\n",
    "        if j == \"texts\":\n",
    "            continue\n",
    "        for i in range(len(examples[\"input_ids\"])):\n",
    "            arr = np.array_split(examples[j][i],2)\n",
    "            dic[j].append(arr[0])\n",
    "            dic[j].append(arr[1])\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2de3d646e7fc4c5897e522ff794e075d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c092d9527697492f8c828df66d8ebedc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test = tokenized_datasets.map(split,remove_columns=[\"input_ids\",\"token_type_ids\",\"attention_mask\",\"labels\",\"texts\"], batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train_dataset = test[\"train\"]\n",
    "full_eval_dataset = test[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_metric\n",
    "import numpy as np\n",
    "metric = load_metric(\"seqeval\")\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    # Remove ignored index (special tokens)\n",
    "    true_predictions = [\n",
    "        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [label_names[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    flattened_results = {\n",
    "        \"overall_precision\": results[\"overall_precision\"],\n",
    "        \"overall_recall\": results[\"overall_recall\"],\n",
    "        \"overall_f1\": results[\"overall_f1\"],\n",
    "        \"overall_accuracy\": results[\"overall_accuracy\"],\n",
    "    }\n",
    "    for k in results.keys():\n",
    "      if(k not in flattened_results.keys()):\n",
    "        flattened_results[k+\"_f1\"]=results[k][\"f1\"]\n",
    "\n",
    "    return flattened_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=6,\n",
    "    per_device_eval_batch_size=6,\n",
    "    num_train_epochs=100,\n",
    "    weight_decay=0.01,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model=model, args=training_args, train_dataset=full_train_dataset, eval_dataset=full_eval_dataset,compute_metrics=compute_metrics, data_collator=data_collator,\n",
    "    tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 78\n",
      "  Num Epochs = 100\n",
      "  Instantaneous batch size per device = 6\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 6\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1300\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1300' max='1300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1300/1300 07:11, Epoch 100/100]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Overall Precision</th>\n",
       "      <th>Overall Recall</th>\n",
       "      <th>Overall F1</th>\n",
       "      <th>Overall Accuracy</th>\n",
       "      <th>Location F1</th>\n",
       "      <th>Location Assosiation F1</th>\n",
       "      <th>Location City F1</th>\n",
       "      <th>Location Country F1</th>\n",
       "      <th>Location Street F1</th>\n",
       "      <th>Organization F1</th>\n",
       "      <th>Person Age F1</th>\n",
       "      <th>Person Firstname F1</th>\n",
       "      <th>Person Lastname F1</th>\n",
       "      <th>Sentence End F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.522151</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.884777</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.263374</td>\n",
       "      <td>0.970000</td>\n",
       "      <td>0.527174</td>\n",
       "      <td>0.683099</td>\n",
       "      <td>0.941637</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.674419</td>\n",
       "      <td>0.953757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.140578</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.817935</td>\n",
       "      <td>0.855114</td>\n",
       "      <td>0.968412</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.557377</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.945455</td>\n",
       "      <td>0.918367</td>\n",
       "      <td>0.838095</td>\n",
       "      <td>0.965714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.106336</td>\n",
       "      <td>0.823678</td>\n",
       "      <td>0.888587</td>\n",
       "      <td>0.854902</td>\n",
       "      <td>0.970217</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.676471</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.953271</td>\n",
       "      <td>0.890756</td>\n",
       "      <td>0.963173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.086727</td>\n",
       "      <td>0.833753</td>\n",
       "      <td>0.899457</td>\n",
       "      <td>0.865359</td>\n",
       "      <td>0.973526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.779661</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990291</td>\n",
       "      <td>0.905983</td>\n",
       "      <td>0.968839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.079236</td>\n",
       "      <td>0.837838</td>\n",
       "      <td>0.926630</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.976835</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.325581</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.971963</td>\n",
       "      <td>0.913793</td>\n",
       "      <td>0.974648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.086754</td>\n",
       "      <td>0.845387</td>\n",
       "      <td>0.921196</td>\n",
       "      <td>0.881664</td>\n",
       "      <td>0.974428</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.807018</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.971963</td>\n",
       "      <td>0.929825</td>\n",
       "      <td>0.971910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.085261</td>\n",
       "      <td>0.866324</td>\n",
       "      <td>0.915761</td>\n",
       "      <td>0.890357</td>\n",
       "      <td>0.975030</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.487805</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.939130</td>\n",
       "      <td>0.965517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.077089</td>\n",
       "      <td>0.870324</td>\n",
       "      <td>0.948370</td>\n",
       "      <td>0.907672</td>\n",
       "      <td>0.978941</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.971591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.082003</td>\n",
       "      <td>0.856790</td>\n",
       "      <td>0.942935</td>\n",
       "      <td>0.897801</td>\n",
       "      <td>0.978039</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990291</td>\n",
       "      <td>0.938053</td>\n",
       "      <td>0.971751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.090579</td>\n",
       "      <td>0.857500</td>\n",
       "      <td>0.932065</td>\n",
       "      <td>0.893229</td>\n",
       "      <td>0.976534</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990291</td>\n",
       "      <td>0.918919</td>\n",
       "      <td>0.974504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.120269</td>\n",
       "      <td>0.838164</td>\n",
       "      <td>0.942935</td>\n",
       "      <td>0.887468</td>\n",
       "      <td>0.974428</td>\n",
       "      <td>0.311111</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.564103</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.927273</td>\n",
       "      <td>0.971591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.096771</td>\n",
       "      <td>0.870000</td>\n",
       "      <td>0.945652</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.977437</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980769</td>\n",
       "      <td>0.940171</td>\n",
       "      <td>0.971751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.107017</td>\n",
       "      <td>0.846914</td>\n",
       "      <td>0.932065</td>\n",
       "      <td>0.887451</td>\n",
       "      <td>0.975331</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.564103</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990291</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.971910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.094732</td>\n",
       "      <td>0.872449</td>\n",
       "      <td>0.929348</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.977738</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>0.968661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.104113</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.932065</td>\n",
       "      <td>0.902632</td>\n",
       "      <td>0.978640</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.935780</td>\n",
       "      <td>0.971591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.121797</td>\n",
       "      <td>0.867168</td>\n",
       "      <td>0.940217</td>\n",
       "      <td>0.902216</td>\n",
       "      <td>0.977437</td>\n",
       "      <td>0.342857</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.945455</td>\n",
       "      <td>0.969014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.129232</td>\n",
       "      <td>0.862843</td>\n",
       "      <td>0.940217</td>\n",
       "      <td>0.899870</td>\n",
       "      <td>0.976233</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.763636</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.945455</td>\n",
       "      <td>0.969014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.112178</td>\n",
       "      <td>0.887728</td>\n",
       "      <td>0.923913</td>\n",
       "      <td>0.905459</td>\n",
       "      <td>0.978339</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.954955</td>\n",
       "      <td>0.971751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.119155</td>\n",
       "      <td>0.876263</td>\n",
       "      <td>0.942935</td>\n",
       "      <td>0.908377</td>\n",
       "      <td>0.978941</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.851852</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.974504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.116180</td>\n",
       "      <td>0.868020</td>\n",
       "      <td>0.929348</td>\n",
       "      <td>0.897638</td>\n",
       "      <td>0.977437</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.754717</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990291</td>\n",
       "      <td>0.946429</td>\n",
       "      <td>0.974359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.133421</td>\n",
       "      <td>0.852941</td>\n",
       "      <td>0.945652</td>\n",
       "      <td>0.896907</td>\n",
       "      <td>0.976835</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.594595</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.125140</td>\n",
       "      <td>0.875648</td>\n",
       "      <td>0.918478</td>\n",
       "      <td>0.896552</td>\n",
       "      <td>0.976835</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.606061</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.954955</td>\n",
       "      <td>0.969014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.124952</td>\n",
       "      <td>0.872123</td>\n",
       "      <td>0.926630</td>\n",
       "      <td>0.898551</td>\n",
       "      <td>0.976534</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.763636</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.606061</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.971751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.126322</td>\n",
       "      <td>0.859259</td>\n",
       "      <td>0.945652</td>\n",
       "      <td>0.900388</td>\n",
       "      <td>0.976233</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.763636</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.969014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.120373</td>\n",
       "      <td>0.868687</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>0.900524</td>\n",
       "      <td>0.976835</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.931034</td>\n",
       "      <td>0.971751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.120379</td>\n",
       "      <td>0.869898</td>\n",
       "      <td>0.926630</td>\n",
       "      <td>0.897368</td>\n",
       "      <td>0.978039</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.606061</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.971751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.123863</td>\n",
       "      <td>0.864662</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.899609</td>\n",
       "      <td>0.978339</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.955752</td>\n",
       "      <td>0.969188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.129290</td>\n",
       "      <td>0.869347</td>\n",
       "      <td>0.940217</td>\n",
       "      <td>0.903394</td>\n",
       "      <td>0.979242</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.628571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990291</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.969188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.131472</td>\n",
       "      <td>0.859649</td>\n",
       "      <td>0.932065</td>\n",
       "      <td>0.894394</td>\n",
       "      <td>0.978039</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.628571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990291</td>\n",
       "      <td>0.954955</td>\n",
       "      <td>0.971910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.124749</td>\n",
       "      <td>0.879699</td>\n",
       "      <td>0.953804</td>\n",
       "      <td>0.915254</td>\n",
       "      <td>0.980144</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990291</td>\n",
       "      <td>0.955752</td>\n",
       "      <td>0.977401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.127505</td>\n",
       "      <td>0.868812</td>\n",
       "      <td>0.953804</td>\n",
       "      <td>0.909326</td>\n",
       "      <td>0.978941</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990291</td>\n",
       "      <td>0.939130</td>\n",
       "      <td>0.974648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.120551</td>\n",
       "      <td>0.872180</td>\n",
       "      <td>0.945652</td>\n",
       "      <td>0.907432</td>\n",
       "      <td>0.978941</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990291</td>\n",
       "      <td>0.938053</td>\n",
       "      <td>0.971751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.117610</td>\n",
       "      <td>0.875949</td>\n",
       "      <td>0.940217</td>\n",
       "      <td>0.906946</td>\n",
       "      <td>0.978941</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990291</td>\n",
       "      <td>0.946429</td>\n",
       "      <td>0.971751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.120887</td>\n",
       "      <td>0.891473</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.913907</td>\n",
       "      <td>0.980144</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.689655</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990291</td>\n",
       "      <td>0.954955</td>\n",
       "      <td>0.974648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.116302</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>0.911258</td>\n",
       "      <td>0.980144</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990291</td>\n",
       "      <td>0.954955</td>\n",
       "      <td>0.974648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.132922</td>\n",
       "      <td>0.869136</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.910737</td>\n",
       "      <td>0.979242</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.851852</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990291</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.963380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.136694</td>\n",
       "      <td>0.866995</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.909561</td>\n",
       "      <td>0.978640</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.836364</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990291</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.963380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.061000</td>\n",
       "      <td>0.130198</td>\n",
       "      <td>0.877193</td>\n",
       "      <td>0.951087</td>\n",
       "      <td>0.912647</td>\n",
       "      <td>0.980144</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.836364</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990291</td>\n",
       "      <td>0.964912</td>\n",
       "      <td>0.963380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.061000</td>\n",
       "      <td>0.133046</td>\n",
       "      <td>0.883420</td>\n",
       "      <td>0.926630</td>\n",
       "      <td>0.904509</td>\n",
       "      <td>0.978339</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990291</td>\n",
       "      <td>0.954955</td>\n",
       "      <td>0.963380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.061000</td>\n",
       "      <td>0.136731</td>\n",
       "      <td>0.880407</td>\n",
       "      <td>0.940217</td>\n",
       "      <td>0.909330</td>\n",
       "      <td>0.979844</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990291</td>\n",
       "      <td>0.973451</td>\n",
       "      <td>0.963380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.061000</td>\n",
       "      <td>0.138606</td>\n",
       "      <td>0.879487</td>\n",
       "      <td>0.932065</td>\n",
       "      <td>0.905013</td>\n",
       "      <td>0.978941</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990291</td>\n",
       "      <td>0.954955</td>\n",
       "      <td>0.963380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.061000</td>\n",
       "      <td>0.138387</td>\n",
       "      <td>0.875949</td>\n",
       "      <td>0.940217</td>\n",
       "      <td>0.906946</td>\n",
       "      <td>0.979242</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990291</td>\n",
       "      <td>0.955752</td>\n",
       "      <td>0.963380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.061000</td>\n",
       "      <td>0.138902</td>\n",
       "      <td>0.876574</td>\n",
       "      <td>0.945652</td>\n",
       "      <td>0.909804</td>\n",
       "      <td>0.979844</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990291</td>\n",
       "      <td>0.964912</td>\n",
       "      <td>0.963380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.061000</td>\n",
       "      <td>0.138614</td>\n",
       "      <td>0.878173</td>\n",
       "      <td>0.940217</td>\n",
       "      <td>0.908136</td>\n",
       "      <td>0.979543</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990291</td>\n",
       "      <td>0.954955</td>\n",
       "      <td>0.963380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.061000</td>\n",
       "      <td>0.138738</td>\n",
       "      <td>0.879177</td>\n",
       "      <td>0.929348</td>\n",
       "      <td>0.903567</td>\n",
       "      <td>0.978640</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990291</td>\n",
       "      <td>0.945455</td>\n",
       "      <td>0.963380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.061000</td>\n",
       "      <td>0.139384</td>\n",
       "      <td>0.880407</td>\n",
       "      <td>0.940217</td>\n",
       "      <td>0.909330</td>\n",
       "      <td>0.979844</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990291</td>\n",
       "      <td>0.954955</td>\n",
       "      <td>0.963380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.061000</td>\n",
       "      <td>0.143079</td>\n",
       "      <td>0.879397</td>\n",
       "      <td>0.951087</td>\n",
       "      <td>0.913838</td>\n",
       "      <td>0.980144</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990291</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.963380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.061000</td>\n",
       "      <td>0.144136</td>\n",
       "      <td>0.875949</td>\n",
       "      <td>0.940217</td>\n",
       "      <td>0.906946</td>\n",
       "      <td>0.979242</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990291</td>\n",
       "      <td>0.954955</td>\n",
       "      <td>0.963380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.061000</td>\n",
       "      <td>0.146137</td>\n",
       "      <td>0.873737</td>\n",
       "      <td>0.940217</td>\n",
       "      <td>0.905759</td>\n",
       "      <td>0.978640</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990291</td>\n",
       "      <td>0.973451</td>\n",
       "      <td>0.963380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>0.061000</td>\n",
       "      <td>0.152764</td>\n",
       "      <td>0.869347</td>\n",
       "      <td>0.940217</td>\n",
       "      <td>0.903394</td>\n",
       "      <td>0.978039</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990291</td>\n",
       "      <td>0.946429</td>\n",
       "      <td>0.960674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.061000</td>\n",
       "      <td>0.156188</td>\n",
       "      <td>0.876923</td>\n",
       "      <td>0.929348</td>\n",
       "      <td>0.902375</td>\n",
       "      <td>0.977136</td>\n",
       "      <td>0.206897</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990291</td>\n",
       "      <td>0.935780</td>\n",
       "      <td>0.960674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.061000</td>\n",
       "      <td>0.149362</td>\n",
       "      <td>0.884319</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>0.908851</td>\n",
       "      <td>0.978339</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990291</td>\n",
       "      <td>0.945455</td>\n",
       "      <td>0.969014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.061000</td>\n",
       "      <td>0.148036</td>\n",
       "      <td>0.877551</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>0.905263</td>\n",
       "      <td>0.978640</td>\n",
       "      <td>0.206897</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990291</td>\n",
       "      <td>0.954955</td>\n",
       "      <td>0.963380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.061000</td>\n",
       "      <td>0.150921</td>\n",
       "      <td>0.873418</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.904325</td>\n",
       "      <td>0.978339</td>\n",
       "      <td>0.193548</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990291</td>\n",
       "      <td>0.954955</td>\n",
       "      <td>0.966292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.061000</td>\n",
       "      <td>0.150919</td>\n",
       "      <td>0.873418</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.904325</td>\n",
       "      <td>0.978339</td>\n",
       "      <td>0.193548</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990291</td>\n",
       "      <td>0.954955</td>\n",
       "      <td>0.966292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.061000</td>\n",
       "      <td>0.150808</td>\n",
       "      <td>0.871537</td>\n",
       "      <td>0.940217</td>\n",
       "      <td>0.904575</td>\n",
       "      <td>0.978339</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990291</td>\n",
       "      <td>0.946429</td>\n",
       "      <td>0.966292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.061000</td>\n",
       "      <td>0.151720</td>\n",
       "      <td>0.871537</td>\n",
       "      <td>0.940217</td>\n",
       "      <td>0.904575</td>\n",
       "      <td>0.978339</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990291</td>\n",
       "      <td>0.946429</td>\n",
       "      <td>0.966292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.061000</td>\n",
       "      <td>0.145655</td>\n",
       "      <td>0.870324</td>\n",
       "      <td>0.948370</td>\n",
       "      <td>0.907672</td>\n",
       "      <td>0.978941</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990291</td>\n",
       "      <td>0.940171</td>\n",
       "      <td>0.969014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.061000</td>\n",
       "      <td>0.145139</td>\n",
       "      <td>0.873134</td>\n",
       "      <td>0.953804</td>\n",
       "      <td>0.911688</td>\n",
       "      <td>0.978640</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990291</td>\n",
       "      <td>0.924370</td>\n",
       "      <td>0.974648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>0.061000</td>\n",
       "      <td>0.146024</td>\n",
       "      <td>0.884319</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>0.908851</td>\n",
       "      <td>0.978339</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990291</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>0.974648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>0.061000</td>\n",
       "      <td>0.146152</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.978941</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990291</td>\n",
       "      <td>0.935780</td>\n",
       "      <td>0.974648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>0.061000</td>\n",
       "      <td>0.145485</td>\n",
       "      <td>0.886598</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>0.910053</td>\n",
       "      <td>0.978640</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990291</td>\n",
       "      <td>0.935780</td>\n",
       "      <td>0.977401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.061000</td>\n",
       "      <td>0.147880</td>\n",
       "      <td>0.886598</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>0.910053</td>\n",
       "      <td>0.978640</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990291</td>\n",
       "      <td>0.935780</td>\n",
       "      <td>0.977401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>0.061000</td>\n",
       "      <td>0.148918</td>\n",
       "      <td>0.882952</td>\n",
       "      <td>0.942935</td>\n",
       "      <td>0.911958</td>\n",
       "      <td>0.979242</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990291</td>\n",
       "      <td>0.946429</td>\n",
       "      <td>0.977401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>0.061000</td>\n",
       "      <td>0.143909</td>\n",
       "      <td>0.886598</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>0.910053</td>\n",
       "      <td>0.978640</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990291</td>\n",
       "      <td>0.938053</td>\n",
       "      <td>0.977401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>0.061000</td>\n",
       "      <td>0.141259</td>\n",
       "      <td>0.891192</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>0.912467</td>\n",
       "      <td>0.978941</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990291</td>\n",
       "      <td>0.936937</td>\n",
       "      <td>0.977401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>0.061000</td>\n",
       "      <td>0.149725</td>\n",
       "      <td>0.876263</td>\n",
       "      <td>0.942935</td>\n",
       "      <td>0.908377</td>\n",
       "      <td>0.978339</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.628571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990291</td>\n",
       "      <td>0.938053</td>\n",
       "      <td>0.977401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>0.061000</td>\n",
       "      <td>0.144870</td>\n",
       "      <td>0.891753</td>\n",
       "      <td>0.940217</td>\n",
       "      <td>0.915344</td>\n",
       "      <td>0.979543</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990291</td>\n",
       "      <td>0.946429</td>\n",
       "      <td>0.977401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.061000</td>\n",
       "      <td>0.142288</td>\n",
       "      <td>0.889460</td>\n",
       "      <td>0.940217</td>\n",
       "      <td>0.914135</td>\n",
       "      <td>0.979543</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990291</td>\n",
       "      <td>0.946429</td>\n",
       "      <td>0.977401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>0.061000</td>\n",
       "      <td>0.141414</td>\n",
       "      <td>0.878173</td>\n",
       "      <td>0.940217</td>\n",
       "      <td>0.908136</td>\n",
       "      <td>0.978339</td>\n",
       "      <td>0.258065</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990291</td>\n",
       "      <td>0.938053</td>\n",
       "      <td>0.974648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>0.061000</td>\n",
       "      <td>0.148638</td>\n",
       "      <td>0.864865</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.908387</td>\n",
       "      <td>0.978039</td>\n",
       "      <td>0.378378</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.851852</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990291</td>\n",
       "      <td>0.929825</td>\n",
       "      <td>0.969014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>0.061000</td>\n",
       "      <td>0.143217</td>\n",
       "      <td>0.875312</td>\n",
       "      <td>0.953804</td>\n",
       "      <td>0.912874</td>\n",
       "      <td>0.978941</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990291</td>\n",
       "      <td>0.938053</td>\n",
       "      <td>0.974648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>0.061000</td>\n",
       "      <td>0.142915</td>\n",
       "      <td>0.877863</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.906702</td>\n",
       "      <td>0.978339</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.606061</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990291</td>\n",
       "      <td>0.935780</td>\n",
       "      <td>0.974648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.061000</td>\n",
       "      <td>0.143648</td>\n",
       "      <td>0.874372</td>\n",
       "      <td>0.945652</td>\n",
       "      <td>0.908616</td>\n",
       "      <td>0.978640</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.606061</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990291</td>\n",
       "      <td>0.938053</td>\n",
       "      <td>0.974648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>0.061000</td>\n",
       "      <td>0.145086</td>\n",
       "      <td>0.876884</td>\n",
       "      <td>0.948370</td>\n",
       "      <td>0.911227</td>\n",
       "      <td>0.978941</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990291</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.974648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.146015</td>\n",
       "      <td>0.876884</td>\n",
       "      <td>0.948370</td>\n",
       "      <td>0.911227</td>\n",
       "      <td>0.978941</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990291</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.974648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.147281</td>\n",
       "      <td>0.876884</td>\n",
       "      <td>0.948370</td>\n",
       "      <td>0.911227</td>\n",
       "      <td>0.978941</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990291</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.974648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.149015</td>\n",
       "      <td>0.883838</td>\n",
       "      <td>0.951087</td>\n",
       "      <td>0.916230</td>\n",
       "      <td>0.979242</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990291</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.974648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.145088</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.945652</td>\n",
       "      <td>0.910995</td>\n",
       "      <td>0.978339</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990291</td>\n",
       "      <td>0.938053</td>\n",
       "      <td>0.974648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.144258</td>\n",
       "      <td>0.879093</td>\n",
       "      <td>0.948370</td>\n",
       "      <td>0.912418</td>\n",
       "      <td>0.978640</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990291</td>\n",
       "      <td>0.938053</td>\n",
       "      <td>0.974648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.143105</td>\n",
       "      <td>0.879093</td>\n",
       "      <td>0.948370</td>\n",
       "      <td>0.912418</td>\n",
       "      <td>0.978941</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990291</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.974648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.143047</td>\n",
       "      <td>0.879093</td>\n",
       "      <td>0.948370</td>\n",
       "      <td>0.912418</td>\n",
       "      <td>0.978941</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990291</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.974648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.147578</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.978941</td>\n",
       "      <td>0.387097</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990291</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.974648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.149473</td>\n",
       "      <td>0.877805</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.915475</td>\n",
       "      <td>0.978640</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990291</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.974648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.149141</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.978941</td>\n",
       "      <td>0.387097</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990291</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.974648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.148304</td>\n",
       "      <td>0.884422</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.919060</td>\n",
       "      <td>0.979543</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990291</td>\n",
       "      <td>0.955752</td>\n",
       "      <td>0.974648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.148694</td>\n",
       "      <td>0.884422</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.919060</td>\n",
       "      <td>0.979543</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990291</td>\n",
       "      <td>0.955752</td>\n",
       "      <td>0.974648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.148407</td>\n",
       "      <td>0.880102</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.907895</td>\n",
       "      <td>0.978039</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.936937</td>\n",
       "      <td>0.974648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.149661</td>\n",
       "      <td>0.880102</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.907895</td>\n",
       "      <td>0.978039</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.936937</td>\n",
       "      <td>0.974648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.147855</td>\n",
       "      <td>0.880711</td>\n",
       "      <td>0.942935</td>\n",
       "      <td>0.910761</td>\n",
       "      <td>0.978640</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990291</td>\n",
       "      <td>0.946429</td>\n",
       "      <td>0.974648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.147951</td>\n",
       "      <td>0.881313</td>\n",
       "      <td>0.948370</td>\n",
       "      <td>0.913613</td>\n",
       "      <td>0.979242</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990291</td>\n",
       "      <td>0.955752</td>\n",
       "      <td>0.974648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.148205</td>\n",
       "      <td>0.879093</td>\n",
       "      <td>0.948370</td>\n",
       "      <td>0.912418</td>\n",
       "      <td>0.978941</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990291</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.974648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.148573</td>\n",
       "      <td>0.879093</td>\n",
       "      <td>0.948370</td>\n",
       "      <td>0.912418</td>\n",
       "      <td>0.978941</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990291</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.974648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.148777</td>\n",
       "      <td>0.879093</td>\n",
       "      <td>0.948370</td>\n",
       "      <td>0.912418</td>\n",
       "      <td>0.978941</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990291</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.974648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.148778</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.945652</td>\n",
       "      <td>0.910995</td>\n",
       "      <td>0.978640</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990291</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.974648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.148873</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.945652</td>\n",
       "      <td>0.910995</td>\n",
       "      <td>0.978640</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990291</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.974648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.148924</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.945652</td>\n",
       "      <td>0.910995</td>\n",
       "      <td>0.978640</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990291</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.974648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.148965</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.945652</td>\n",
       "      <td>0.910995</td>\n",
       "      <td>0.978640</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990291</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.974648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.148989</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.945652</td>\n",
       "      <td>0.910995</td>\n",
       "      <td>0.978640</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990291</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.974648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "/usr/local/lib/python3.8/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "Saving model checkpoint to ./results/checkpoint-500\n",
      "Configuration saved in ./results/checkpoint-500/config.json\n",
      "Model weights saved in ./results/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-500/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "Saving model checkpoint to ./results/checkpoint-1000\n",
      "Configuration saved in ./results/checkpoint-1000/config.json\n",
      "Model weights saved in ./results/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-1000/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1300, training_loss=0.02402842131944803, metrics={'train_runtime': 433.2059, 'train_samples_per_second': 18.005, 'train_steps_per_second': 3.001, 'total_flos': 5100007352740956.0, 'train_loss': 0.02402842131944803, 'epoch': 100.0})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.1489889919757843,\n",
       " 'eval_overall_precision': 0.8787878787878788,\n",
       " 'eval_overall_recall': 0.9456521739130435,\n",
       " 'eval_overall_f1': 0.9109947643979057,\n",
       " 'eval_overall_accuracy': 0.9786401925391095,\n",
       " 'eval_LOCATION_f1': 0.26666666666666666,\n",
       " 'eval_LOCATION_ASSOSIATION_f1': 0.7058823529411765,\n",
       " 'eval_LOCATION_CITY_f1': 0.8301886792452831,\n",
       " 'eval_LOCATION_COUNTRY_f1': 0.6666666666666666,\n",
       " 'eval_LOCATION_STREET_f1': 0.4,\n",
       " 'eval_ORGANIZATION_f1': 0.625,\n",
       " 'eval_PERSON_AGE_f1': 1.0,\n",
       " 'eval_PERSON_FIRSTNAME_f1': 0.9902912621359222,\n",
       " 'eval_PERSON_LASTNAME_f1': 0.9473684210526315,\n",
       " 'eval_SENTENCE_END_f1': 0.9746478873239437,\n",
       " 'eval_runtime': 0.2839,\n",
       " 'eval_samples_per_second': 70.44,\n",
       " 'eval_steps_per_second': 14.088,\n",
       " 'epoch': 100.0}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./NEWS_NER_2/config.json\n",
      "Model weights saved in ./NEWS_NER_2/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "model.save_pretrained('./NEWS_NER_2/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in ./NEWS_TOK_2/tokenizer_config.json\n",
      "Special tokens file saved in ./NEWS_TOK_2/special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./NEWS_TOK_2/tokenizer_config.json',\n",
       " './NEWS_TOK_2/special_tokens_map.json',\n",
       " './NEWS_TOK_2/vocab.txt',\n",
       " './NEWS_TOK_2/added_tokens.json',\n",
       " './NEWS_TOK_2/tokenizer.json')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_pretrained('./NEWS_TOK_2/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.11371712386608124,\n",
       " 'eval_overall_precision': 0.8902077151335311,\n",
       " 'eval_overall_recall': 0.9433962264150944,\n",
       " 'eval_overall_f1': 0.916030534351145,\n",
       " 'eval_overall_accuracy': 0.982909090909091,\n",
       " 'eval_LOCATION_f1': 0.2727272727272727,\n",
       " 'eval_LOCATION_ASSOSIATION_f1': 0.6666666666666666,\n",
       " 'eval_LOCATION_CITY_f1': 0.8823529411764706,\n",
       " 'eval_LOCATION_COUNTRY_f1': 0.5,\n",
       " 'eval_LOCATION_STREET_f1': 1.0,\n",
       " 'eval_ORGANIZATION_f1': 0.6086956521739131,\n",
       " 'eval_PERSON_AGE_f1': 1.0,\n",
       " 'eval_PERSON_FIRSTNAME_f1': 1.0,\n",
       " 'eval_PERSON_LASTNAME_f1': 0.9600000000000001,\n",
       " 'eval_SENTENCE_END_f1': 0.9822064056939502,\n",
       " 'eval_runtime': 0.2295,\n",
       " 'eval_samples_per_second': 43.569,\n",
       " 'eval_steps_per_second': 8.714,\n",
       " 'epoch': 100.0}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{'eval_loss': 0.11371712386608124,\n",
    " 'eval_overall_precision': 0.8902077151335311,\n",
    " 'eval_overall_recall': 0.9433962264150944,\n",
    " 'eval_overall_f1': 0.916030534351145,\n",
    " 'eval_overall_accuracy': 0.982909090909091,\n",
    " 'eval_LOCATION_f1': 0.2727272727272727,\n",
    " 'eval_LOCATION_ASSOSIATION_f1': 0.6666666666666666,\n",
    " 'eval_LOCATION_CITY_f1': 0.8823529411764706,\n",
    " 'eval_LOCATION_COUNTRY_f1': 0.5,\n",
    " 'eval_LOCATION_STREET_f1': 1.0,\n",
    " 'eval_ORGANIZATION_f1': 0.6086956521739131,\n",
    " 'eval_PERSON_AGE_f1': 1.0,\n",
    " 'eval_PERSON_FIRSTNAME_f1': 1.0,\n",
    " 'eval_PERSON_LASTNAME_f1': 0.9600000000000001,\n",
    " 'eval_SENTENCE_END_f1': 0.9822064056939502,\n",
    " 'eval_runtime': 0.2295,\n",
    " 'eval_samples_per_second': 43.569,\n",
    " 'eval_steps_per_second': 8.714,\n",
    " 'epoch': 100.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.13603897392749786,\n",
       " 'eval_overall_precision': 0.8922651933701657,\n",
       " 'eval_overall_recall': 0.930835734870317,\n",
       " 'eval_overall_f1': 0.9111424541607898,\n",
       " 'eval_overall_accuracy': 0.9815531091936923,\n",
       " 'eval_LOCATION_f1': 0.32,\n",
       " 'eval_LOCATION_ASSOSIATION_f1': 0.47058823529411764,\n",
       " 'eval_LOCATION_CITY_f1': 0.851851851851852,\n",
       " 'eval_LOCATION_COUNTRY_f1': 0.8,\n",
       " 'eval_LOCATION_STREET_f1': 0.7692307692307693,\n",
       " 'eval_ORGANIZATION_f1': 0.75,\n",
       " 'eval_PERSON_AGE_f1': 0.9230769230769231,\n",
       " 'eval_PERSON_FIRSTNAME_f1': 0.9538461538461539,\n",
       " 'eval_PERSON_LASTNAME_f1': 0.9863013698630138,\n",
       " 'eval_SENTENCE_END_f1': 0.9915966386554621,\n",
       " 'eval_TELE_NUMMER_f1': 0.75,\n",
       " 'eval_runtime': 0.3311,\n",
       " 'eval_samples_per_second': 60.409,\n",
       " 'eval_steps_per_second': 12.082,\n",
       " 'epoch': 100.0}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{'eval_loss': 0.13603897392749786,\n",
    " 'eval_overall_precision': 0.8922651933701657,\n",
    " 'eval_overall_recall': 0.930835734870317,\n",
    " 'eval_overall_f1': 0.9111424541607898,\n",
    " 'eval_overall_accuracy': 0.9815531091936923,\n",
    " 'eval_LOCATION_f1': 0.32,\n",
    " 'eval_LOCATION_ASSOSIATION_f1': 0.47058823529411764,\n",
    " 'eval_LOCATION_CITY_f1': 0.851851851851852,\n",
    " 'eval_LOCATION_COUNTRY_f1': 0.8,\n",
    " 'eval_LOCATION_STREET_f1': 0.7692307692307693,\n",
    " 'eval_ORGANIZATION_f1': 0.75,\n",
    " 'eval_PERSON_AGE_f1': 0.9230769230769231,\n",
    " 'eval_PERSON_FIRSTNAME_f1': 0.9538461538461539,\n",
    " 'eval_PERSON_LASTNAME_f1': 0.9863013698630138,\n",
    " 'eval_SENTENCE_END_f1': 0.9915966386554621,\n",
    " 'eval_TELE_NUMMER_f1': 0.75,\n",
    " 'eval_runtime': 0.3311,\n",
    " 'eval_samples_per_second': 60.409,\n",
    " 'eval_steps_per_second': 12.082,\n",
    " 'epoch': 100.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.12491893023252487,\n",
       " 'eval_overall_precision': 0.8971291866028708,\n",
       " 'eval_overall_recall': 0.9375,\n",
       " 'eval_overall_f1': 0.9168704156479217,\n",
       " 'eval_overall_accuracy': 0.9827833572453372,\n",
       " 'eval_LOCATION_f1': 0.125,\n",
       " 'eval_LOCATION_ASSOSIATION_f1': 0.5454545454545454,\n",
       " 'eval_LOCATION_CITY_f1': 0.8333333333333334,\n",
       " 'eval_LOCATION_COUNTRY_f1': 0.28571428571428575,\n",
       " 'eval_LOCATION_STREET_f1': 0.7777777777777778,\n",
       " 'eval_ORGANIZATION_f1': 0.6153846153846153,\n",
       " 'eval_PERSON_AGE_f1': 0.9818181818181818,\n",
       " 'eval_PERSON_FIRSTNAME_f1': 0.9642857142857143,\n",
       " 'eval_PERSON_LASTNAME_f1': 0.9523809523809523,\n",
       " 'eval_SENTENCE_END_f1': 0.9892473118279571,\n",
       " 'eval_TELE_NUMMER_f1': 1.0,\n",
       " 'eval_runtime': 0.9958,\n",
       " 'eval_samples_per_second': 172.731,\n",
       " 'eval_steps_per_second': 29.123,\n",
       " 'epoch': 20.0}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{'eval_loss': 0.12491893023252487,\n",
    " 'eval_overall_precision': 0.8971291866028708,\n",
    " 'eval_overall_recall': 0.9375,\n",
    " 'eval_overall_f1': 0.9168704156479217,\n",
    " 'eval_overall_accuracy': 0.9827833572453372,\n",
    " 'eval_LOCATION_f1': 0.125,\n",
    " 'eval_LOCATION_ASSOSIATION_f1': 0.5454545454545454,\n",
    " 'eval_LOCATION_CITY_f1': 0.8333333333333334,\n",
    " 'eval_LOCATION_COUNTRY_f1': 0.28571428571428575,\n",
    " 'eval_LOCATION_STREET_f1': 0.7777777777777778,\n",
    " 'eval_ORGANIZATION_f1': 0.6153846153846153,\n",
    " 'eval_PERSON_AGE_f1': 0.9818181818181818,\n",
    " 'eval_PERSON_FIRSTNAME_f1': 0.9642857142857143,\n",
    " 'eval_PERSON_LASTNAME_f1': 0.9523809523809523,\n",
    " 'eval_SENTENCE_END_f1': 0.9892473118279571,\n",
    " 'eval_TELE_NUMMER_f1': 1.0,\n",
    " 'eval_runtime': 0.9958,\n",
    " 'eval_samples_per_second': 172.731,\n",
    " 'eval_steps_per_second': 29.123,\n",
    " 'epoch': 20.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

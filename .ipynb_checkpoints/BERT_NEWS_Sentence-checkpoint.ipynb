{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizerFast, BertForPreTraining,BertForTokenClassification ,Trainer, TrainingArguments\n",
    "import os\n",
    "import torch \n",
    "import pandas as pd\n",
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from array import array\n",
    "import numpy as np\n",
    "def loadData():\n",
    "    list_subfolders_with_paths = [f.path for f in os.scandir(\"./annotation_sentence\") if f.is_dir()]\n",
    "    data = {\"texts\": [],\"labels\":[]}\n",
    "    for i in list_subfolders_with_paths:\n",
    "    #print(\"new File\")\n",
    "        texts=[]\n",
    "        labels=[]\n",
    "        with open(f\"{i}/admin.conll\",\"r\", encoding=\"utf-8-sig\") as file: \n",
    "            for j in  file.readlines():\n",
    "                if(j.strip() == \"\"):\n",
    "                    continue\n",
    "                sp = j.split(\" \")\n",
    "                if(\"null\" in sp[1].rstrip(\"\\n\")):\n",
    "                    print(i)\n",
    "                texts.append(sp[0])\n",
    "                labels.append(sp[1].rstrip(\"\\n\"))\n",
    "                #print(f\"Text: {sp[0]}\")\n",
    "                #print(f\"Label: {sp[1]}\")\n",
    "            data[\"texts\"].append((texts))\n",
    "            data[\"labels\"].append(( labels))\n",
    "    \n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset , ClassLabel ,Features ,Sequence ,Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata = loadData()\n",
    "texts = traindata[\"texts\"]\n",
    "tags = traindata[\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_tags = set(tag for doc in tags for tag in doc)\n",
    "tag2id = {tag: id for id, tag in enumerate(unique_tags)}\n",
    "id2tag = {id: tag for tag, id in tag2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-SENTENCE', 'O', 'I-SENTENCE']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(unique_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.from_dict(loadData(),features=Features( {\"texts\": Sequence(Value(\"string\")),'labels':Sequence(ClassLabel(names=list(unique_tags),num_classes =len(unique_tags)))}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.train_test_split(test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClassLabel(num_classes=3, names=['B-SENTENCE', 'O', 'I-SENTENCE'], names_file=None, id=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(dataset[\"train\"].features[\"labels\"].feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'texts': ['MITBEWOHNER',\n",
       "  'BERICHTET',\n",
       "  'VOR',\n",
       "  'GERICHT',\n",
       "  'Opfer',\n",
       "  'ging',\n",
       "  'mit',\n",
       "  'Bier',\n",
       "  'und',\n",
       "  'Viagra',\n",
       "  'zum',\n",
       "  'Kannibalen-Date',\n",
       "  'Der',\n",
       "  'Angeklagte',\n",
       "  'Stefan',\n",
       "  'R',\n",
       "  '.',\n",
       "  'am',\n",
       "  'ersten',\n",
       "  'Prozesstag',\n",
       "  '.',\n",
       "  'Laut',\n",
       "  'Anklage',\n",
       "  'tötete',\n",
       "  'er',\n",
       "  'Opfer',\n",
       "  'Stefan',\n",
       "  'T',\n",
       "  '.',\n",
       "  '(',\n",
       "  '43',\n",
       "  ')',\n",
       "  ',',\n",
       "  'weil',\n",
       "  'er',\n",
       "  'dadurch',\n",
       "  'Befriedigung',\n",
       "  'suchte',\n",
       "  'und',\n",
       "  'Teile',\n",
       "  'der',\n",
       "  'Leiche',\n",
       "  'verspeisen',\n",
       "  'wollte',\n",
       "  'Foto',\n",
       "  ':',\n",
       "  'Olaf',\n",
       "  'Wagner',\n",
       "  ',',\n",
       "  'Polizei',\n",
       "  'Berlin',\n",
       "  'Von',\n",
       "  ':',\n",
       "  'ANNE',\n",
       "  'LOSENSKY',\n",
       "  '17.08.2021',\n",
       "  '-',\n",
       "  '17',\n",
       "  ':',\n",
       "  '52',\n",
       "  'Uhr',\n",
       "  'Berlin',\n",
       "  '–',\n",
       "  'Mit',\n",
       "  'frischer',\n",
       "  'Rasur',\n",
       "  ',',\n",
       "  'Viagra',\n",
       "  'und',\n",
       "  'einer',\n",
       "  'Flasche',\n",
       "  'Bier',\n",
       "  'in',\n",
       "  'der',\n",
       "  'Tasche',\n",
       "  ':',\n",
       "  'So',\n",
       "  'brach',\n",
       "  'Monteur',\n",
       "  'Stefan',\n",
       "  'T',\n",
       "  '.',\n",
       "  '(',\n",
       "  '43',\n",
       "  ')',\n",
       "  'zum',\n",
       "  'tödlichen',\n",
       "  'Sex-Date',\n",
       "  'mit',\n",
       "  'dem',\n",
       "  'mutmaßlichen',\n",
       "  'Kannibalen',\n",
       "  'von',\n",
       "  'Berlin',\n",
       "  '-',\n",
       "  'Pankow',\n",
       "  'auf',\n",
       "  '…',\n",
       "  'Tag',\n",
       "  '2',\n",
       "  'im',\n",
       "  'Prozess',\n",
       "  'gegen',\n",
       "  'Mathe-Lehrer',\n",
       "  'Stefan',\n",
       "  'R',\n",
       "  '.',\n",
       "  '(',\n",
       "  '41',\n",
       "  ')',\n",
       "  '.',\n",
       "  'Die',\n",
       "  'Mord-Anklage',\n",
       "  ':',\n",
       "  '„',\n",
       "  'Er',\n",
       "  'tötete',\n",
       "  'in',\n",
       "  'seiner',\n",
       "  'Wohnung',\n",
       "  'Stefan',\n",
       "  'T',\n",
       "  '.',\n",
       "  'auf',\n",
       "  'bislang',\n",
       "  'nicht',\n",
       "  'bekannte',\n",
       "  'Weise',\n",
       "  ',',\n",
       "  'weil',\n",
       "  'er',\n",
       "  'durch',\n",
       "  'die',\n",
       "  'Tötung',\n",
       "  'geschlechtliche',\n",
       "  'Befriedigung',\n",
       "  'suchte',\n",
       "  'und',\n",
       "  'Teile',\n",
       "  'der',\n",
       "  'Leiche',\n",
       "  'verspeisen',\n",
       "  'wollte',\n",
       "  '.',\n",
       "  '“',\n",
       "  'Dem',\n",
       "  'Pankower',\n",
       "  'Privatschullehrer',\n",
       "  'droht',\n",
       "  'lebenslange',\n",
       "  'Haft',\n",
       "  '.',\n",
       "  'Der',\n",
       "  'wortgewandte',\n",
       "  'Pädagoge',\n",
       "  'schweigt',\n",
       "  '.',\n",
       "  'Im',\n",
       "  'grünkarierten',\n",
       "  'Hemd',\n",
       "  'sitzt',\n",
       "  'der',\n",
       "  'massige',\n",
       "  'Mann',\n",
       "  'hinter',\n",
       "  'Panzerglas',\n",
       "  'auf',\n",
       "  'der',\n",
       "  'Anklagebank',\n",
       "  '.',\n",
       "  'Sein',\n",
       "  'Vornamens-Vetter',\n",
       "  'aus',\n",
       "  'Lichtenberg',\n",
       "  'verschwand',\n",
       "  'in',\n",
       "  'der',\n",
       "  'Nacht',\n",
       "  'zum',\n",
       "  '6',\n",
       "  '.',\n",
       "  'September',\n",
       "  '2020',\n",
       "  '.',\n",
       "  'Wochen',\n",
       "  'später',\n",
       "  'fand',\n",
       "  'man',\n",
       "  'die',\n",
       "  'Leichenteile',\n",
       "  'verstreut',\n",
       "  'in',\n",
       "  'Pankow',\n",
       "  '.',\n",
       "  '►',\n",
       "  'DER',\n",
       "  'BESTE',\n",
       "  'FREUND',\n",
       "  'DES',\n",
       "  'OPFERS',\n",
       "  '.',\n",
       "  '„',\n",
       "  'Stefan',\n",
       "  'war',\n",
       "  'ein',\n",
       "  'guter',\n",
       "  'Mensch',\n",
       "  ',',\n",
       "  'lebenslustig',\n",
       "  '“',\n",
       "  ',',\n",
       "  'sagt',\n",
       "  'Zimmermann',\n",
       "  'Jan',\n",
       "  'S',\n",
       "  '.',\n",
       "  '(',\n",
       "  '43',\n",
       "  ')',\n",
       "  '.',\n",
       "  '„',\n",
       "  'Er',\n",
       "  'malte',\n",
       "  ',',\n",
       "  'schnitzte',\n",
       "  'Figürchen',\n",
       "  '.',\n",
       "  'Wir',\n",
       "  'kannten',\n",
       "  'uns',\n",
       "  'ewig',\n",
       "  ',',\n",
       "  'wohnten',\n",
       "  'seit',\n",
       "  'zwei',\n",
       "  'Jahren',\n",
       "  'zusammen',\n",
       "  '.',\n",
       "  'Hatten',\n",
       "  'am',\n",
       "  'Vortag',\n",
       "  'Gäste',\n",
       "  '.',\n",
       "  'Gefeiert',\n",
       "  ',',\n",
       "  'getrunken',\n",
       "  ',',\n",
       "  'Karten',\n",
       "  'gespielt',\n",
       "  ',',\n",
       "  'Musik',\n",
       "  'gehört',\n",
       "  '.',\n",
       "  'Morgens',\n",
       "  'hatte',\n",
       "  'ich',\n",
       "  'einen',\n",
       "  'üblen',\n",
       "  'Kater',\n",
       "  '.',\n",
       "  'Aber',\n",
       "  'Stefan',\n",
       "  'kochte',\n",
       "  'Essen',\n",
       "  '.',\n",
       "  'In',\n",
       "  'der',\n",
       "  'Nacht',\n",
       "  'wollte',\n",
       "  'er',\n",
       "  'noch',\n",
       "  'ein',\n",
       "  'Sex-Date',\n",
       "  'treffen',\n",
       "  '.',\n",
       "  'Verabredet',\n",
       "  'im',\n",
       "  'Internet',\n",
       "  '.',\n",
       "  'Sowas',\n",
       "  'kam',\n",
       "  'öfter',\n",
       "  'vor',\n",
       "  '.',\n",
       "  'Mit',\n",
       "  'wem',\n",
       "  'er',\n",
       "  'sich',\n",
       "  'traf',\n",
       "  ',',\n",
       "  'interessierte',\n",
       "  'mich',\n",
       "  'nicht',\n",
       "  '.',\n",
       "  'Er',\n",
       "  'war',\n",
       "  'bester',\n",
       "  'Laune',\n",
       "  '.',\n",
       "  'Duschte',\n",
       "  'und',\n",
       "  'rasierte',\n",
       "  'sich',\n",
       "  'im',\n",
       "  'Intimbereich',\n",
       "  ',',\n",
       "  'ich',\n",
       "  'sah',\n",
       "  'die',\n",
       "  'Hinterlassenschaft',\n",
       "  'im',\n",
       "  'Bad',\n",
       "  '.',\n",
       "  'Er',\n",
       "  'traf',\n",
       "  'Frauen',\n",
       "  'und',\n",
       "  'Pärchen',\n",
       "  ',',\n",
       "  'auch',\n",
       "  'Prostituierte',\n",
       "  '.',\n",
       "  'Ich',\n",
       "  'wusste',\n",
       "  'nicht',\n",
       "  ',',\n",
       "  'dass',\n",
       "  'er',\n",
       "  'auch',\n",
       "  'Männer',\n",
       "  'traf',\n",
       "  '.',\n",
       "  'Er',\n",
       "  'nahm',\n",
       "  'ein',\n",
       "  'Bier',\n",
       "  'mit',\n",
       "  'und',\n",
       "  'Potenzmittel',\n",
       "  ',',\n",
       "  'verließ',\n",
       "  'die',\n",
       "  'Wohnung',\n",
       "  'und',\n",
       "  'kam',\n",
       "  'nie',\n",
       "  'wieder',\n",
       "  '.',\n",
       "  '“',\n",
       "  '►',\n",
       "  'DER',\n",
       "  'TAXIFAHRER',\n",
       "  '.',\n",
       "  '„',\n",
       "  'Er',\n",
       "  'wollte',\n",
       "  'zur',\n",
       "  'Parkstraße',\n",
       "  'nach',\n",
       "  'Pankow',\n",
       "  '“',\n",
       "  ',',\n",
       "  'erinnert',\n",
       "  'sich',\n",
       "  'Tuncer',\n",
       "  'A',\n",
       "  '.',\n",
       "  '(',\n",
       "  '44',\n",
       "  ')',\n",
       "  'an',\n",
       "  'den',\n",
       "  'Fahrgast',\n",
       "  '.',\n",
       "  '„',\n",
       "  'Ich',\n",
       "  'gab',\n",
       "  'es',\n",
       "  'ins',\n",
       "  'Navi',\n",
       "  'ein',\n",
       "  '.',\n",
       "  'Storkower',\n",
       "  'Straße',\n",
       "  'wollte',\n",
       "  'er',\n",
       "  'aber',\n",
       "  'lieber',\n",
       "  'mit',\n",
       "  'der',\n",
       "  'S-Bahn',\n",
       "  'weiterfahren',\n",
       "  ',',\n",
       "  'stieg',\n",
       "  'aus',\n",
       "  '.',\n",
       "  '“',\n",
       "  '►',\n",
       "  'DER',\n",
       "  'KUMPEL',\n",
       "  '.',\n",
       "  '„',\n",
       "  'Er',\n",
       "  'war',\n",
       "  'Junggeselle',\n",
       "  ',',\n",
       "  'genoss',\n",
       "  'das',\n",
       "  'Leben',\n",
       "  '“',\n",
       "  ',',\n",
       "  'sagt',\n",
       "  'Nico',\n",
       "  'B',\n",
       "  '.',\n",
       "  '(',\n",
       "  '45',\n",
       "  ')',\n",
       "  '.',\n",
       "  '„',\n",
       "  'Er',\n",
       "  'war',\n",
       "  'sexuell',\n",
       "  'sehr',\n",
       "  'aktiv',\n",
       "  '.',\n",
       "  'Seine',\n",
       "  'Vorlieben',\n",
       "  'kannte',\n",
       "  'ich',\n",
       "  'nicht',\n",
       "  '.',\n",
       "  'Mag',\n",
       "  'seine',\n",
       "  'Fesselspiele',\n",
       "  ',',\n",
       "  'aber',\n",
       "  'alles',\n",
       "  'im',\n",
       "  'Rahmen',\n",
       "  '.',\n",
       "  'Ich',\n",
       "  'dachte',\n",
       "  ',',\n",
       "  'er',\n",
       "  'sei',\n",
       "  'hetero',\n",
       "  '.',\n",
       "  'Er',\n",
       "  'war',\n",
       "  'topfit',\n",
       "  ',',\n",
       "  'bis',\n",
       "  'auf',\n",
       "  'sein',\n",
       "  'Asthma',\n",
       "  '.',\n",
       "  'Nahm',\n",
       "  'Viagra',\n",
       "  ',',\n",
       "  'manchmal',\n",
       "  'Kokain',\n",
       "  ',',\n",
       "  'auch',\n",
       "  'Gras',\n",
       "  '.',\n",
       "  '“',\n",
       "  'Eine',\n",
       "  'Verteidigerin',\n",
       "  'zitiert',\n",
       "  ',',\n",
       "  'was',\n",
       "  'er',\n",
       "  'nach',\n",
       "  'dem',\n",
       "  'spurlosen',\n",
       "  'Verschwinden',\n",
       "  'des',\n",
       "  'Freundes',\n",
       "  'vermutet',\n",
       "  'hatte',\n",
       "  ':',\n",
       "  '„',\n",
       "  'Ein',\n",
       "  'Unglück',\n",
       "  'oder',\n",
       "  'Herzinfarkt',\n",
       "  'beim',\n",
       "  'Sextreffen',\n",
       "  ',',\n",
       "  'dann',\n",
       "  'hat',\n",
       "  'man',\n",
       "  'ihn',\n",
       "  'beseitigt',\n",
       "  '.',\n",
       "  '“',\n",
       "  'Nico',\n",
       "  'B',\n",
       "  '.',\n",
       "  'kann',\n",
       "  'sich',\n",
       "  'nicht',\n",
       "  'erklären',\n",
       "  ',',\n",
       "  'wieso',\n",
       "  'er',\n",
       "  'so',\n",
       "  'etwas',\n",
       "  'gesagt',\n",
       "  'haben',\n",
       "  'soll',\n",
       "  '.',\n",
       "  'Das',\n",
       "  'könnte',\n",
       "  'aber',\n",
       "  'die',\n",
       "  'Verteidigungsstrategie',\n",
       "  'des',\n",
       "  'Lehrers',\n",
       "  'sein',\n",
       "  ':',\n",
       "  'Das',\n",
       "  'Zerstückeln',\n",
       "  'einer',\n",
       "  'Leiche',\n",
       "  'zur',\n",
       "  'Verschleierung',\n",
       "  'ist',\n",
       "  'nicht',\n",
       "  'strafbar',\n",
       "  ',',\n",
       "  'entschied',\n",
       "  'der',\n",
       "  'BGH',\n",
       "  '.',\n",
       "  'Weiter',\n",
       "  'Donnerstag',\n",
       "  '.',\n",
       "  'Urteil',\n",
       "  '21',\n",
       "  '.',\n",
       "  'Oktober',\n",
       "  '.',\n",
       "  'MANN',\n",
       "  '(',\n",
       "  '41',\n",
       "  ')',\n",
       "  'IN',\n",
       "  'BERLIN',\n",
       "  'FESTGENOMMEN',\n",
       "  'Ermittler',\n",
       "  'fanden',\n",
       "  'Chemikalien',\n",
       "  'und',\n",
       "  'Knochensäge',\n",
       "  'im',\n",
       "  'Keller',\n",
       "  'Quelle',\n",
       "  ':',\n",
       "  'Bild06.01.2021',\n",
       "  '01',\n",
       "  ':',\n",
       "  '43'],\n",
       " 'labels': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  0,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  0,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  0,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  0,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  0,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  0,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  0,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  0,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  0,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  1,\n",
       "  0,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  0,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  0,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  0,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  0,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  0,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  0,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  0,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  0,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  0,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  0,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  0,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  0,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  0,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  0,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  0,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  1,\n",
       "  0,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  0,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  0,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  0,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  0,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  0,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  1,\n",
       "  0,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  0,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  0,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  0,\n",
       "  2,\n",
       "  2,\n",
       "  0,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = dataset[\"train\"].features[f\"labels\"].feature.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at deepset/gbert-large were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at deepset/gbert-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#Load Model and Tokenizer\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = BertTokenizerFast.from_pretrained('deepset/gbert-large')\n",
    "model = BertForTokenClassification.from_pretrained('deepset/gbert-large', num_labels=len(label_names) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.label2id =  (dataset[\"train\"].features[\"labels\"].feature)._str2int \n",
    "model.config.id2label =  {str(v): k for k, v in (dataset[\"train\"].features[\"labels\"].feature)._str2int.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    #print(examples.keys())\n",
    "    tokenized_inputs = tokenizer(examples[\"texts\"], truncation=True, is_split_into_words=True)\n",
    "\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[\"labels\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)  # Map tokens to their respective word.\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:  # Set the special tokens to -100.\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:  # Only label the first token of a given word.\n",
    "                label_ids.append(label[word_idx])\n",
    "            else:\n",
    "                label_ids.append(-100)\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    \n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ec4cab84481427bb29c91929d1c1f5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82f272a5122949c882399a99108a629e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_datasets = dataset.map(tokenize_and_align_labels, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(examples):\n",
    "    dic ={\"input_ids\":[],\"token_type_ids\":[],\"attention_mask\":[],\"labels\":[]}\n",
    "    for j in examples:\n",
    "        if j == \"texts\":\n",
    "            continue\n",
    "        for i in range(len(examples[\"input_ids\"])):\n",
    "            arr = np.array_split(examples[j][i],2)\n",
    "            dic[j].append(arr[0])\n",
    "            dic[j].append(arr[1])\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2ed15d3187e4a02be040c4cf3ccf45e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd927bc934f04cadb6a774c57048519f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test = tokenized_datasets.map(split,remove_columns=[\"input_ids\",\"token_type_ids\",\"attention_mask\",\"labels\",\"texts\"], batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train_dataset = test[\"train\"]\n",
    "full_eval_dataset = test[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_metric\n",
    "import numpy as np\n",
    "metric = load_metric(\"seqeval\")\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    # Remove ignored index (special tokens)\n",
    "    true_predictions = [\n",
    "        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [label_names[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    flattened_results = {\n",
    "        \"overall_precision\": results[\"overall_precision\"],\n",
    "        \"overall_recall\": results[\"overall_recall\"],\n",
    "        \"overall_f1\": results[\"overall_f1\"],\n",
    "        \"overall_accuracy\": results[\"overall_accuracy\"],\n",
    "    }\n",
    "    for k in results.keys():\n",
    "      if(k not in flattened_results.keys()):\n",
    "        flattened_results[k+\"_f1\"]=results[k][\"f1\"]\n",
    "\n",
    "    return flattened_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=6,\n",
    "    per_device_eval_batch_size=6,\n",
    "    num_train_epochs=100,\n",
    "    weight_decay=0.01,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model=model, args=training_args, train_dataset=full_train_dataset, eval_dataset=full_eval_dataset,compute_metrics=compute_metrics, data_collator=data_collator,\n",
    "    tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 78\n",
      "  Num Epochs = 100\n",
      "  Instantaneous batch size per device = 6\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 6\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1300\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1300' max='1300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1300/1300 06:06, Epoch 100/100]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Overall Precision</th>\n",
       "      <th>Overall Recall</th>\n",
       "      <th>Overall F1</th>\n",
       "      <th>Overall Accuracy</th>\n",
       "      <th>Sentence F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.183055</td>\n",
       "      <td>0.435897</td>\n",
       "      <td>0.406699</td>\n",
       "      <td>0.420792</td>\n",
       "      <td>0.948251</td>\n",
       "      <td>0.420792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.079641</td>\n",
       "      <td>0.637931</td>\n",
       "      <td>0.708134</td>\n",
       "      <td>0.671202</td>\n",
       "      <td>0.971668</td>\n",
       "      <td>0.671202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.055655</td>\n",
       "      <td>0.800866</td>\n",
       "      <td>0.885167</td>\n",
       "      <td>0.840909</td>\n",
       "      <td>0.982943</td>\n",
       "      <td>0.840909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.269498</td>\n",
       "      <td>0.385417</td>\n",
       "      <td>0.354067</td>\n",
       "      <td>0.369077</td>\n",
       "      <td>0.917895</td>\n",
       "      <td>0.369077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.069423</td>\n",
       "      <td>0.721311</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.777042</td>\n",
       "      <td>0.979474</td>\n",
       "      <td>0.777042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.077262</td>\n",
       "      <td>0.852535</td>\n",
       "      <td>0.885167</td>\n",
       "      <td>0.868545</td>\n",
       "      <td>0.982654</td>\n",
       "      <td>0.868545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.082116</td>\n",
       "      <td>0.870370</td>\n",
       "      <td>0.899522</td>\n",
       "      <td>0.884706</td>\n",
       "      <td>0.983232</td>\n",
       "      <td>0.884706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.088999</td>\n",
       "      <td>0.856481</td>\n",
       "      <td>0.885167</td>\n",
       "      <td>0.870588</td>\n",
       "      <td>0.979474</td>\n",
       "      <td>0.870588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.079294</td>\n",
       "      <td>0.863014</td>\n",
       "      <td>0.904306</td>\n",
       "      <td>0.883178</td>\n",
       "      <td>0.982654</td>\n",
       "      <td>0.883178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.087105</td>\n",
       "      <td>0.868778</td>\n",
       "      <td>0.918660</td>\n",
       "      <td>0.893023</td>\n",
       "      <td>0.981498</td>\n",
       "      <td>0.893023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.069832</td>\n",
       "      <td>0.832599</td>\n",
       "      <td>0.904306</td>\n",
       "      <td>0.866972</td>\n",
       "      <td>0.983810</td>\n",
       "      <td>0.866972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.066095</td>\n",
       "      <td>0.851351</td>\n",
       "      <td>0.904306</td>\n",
       "      <td>0.877030</td>\n",
       "      <td>0.984389</td>\n",
       "      <td>0.877030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.073448</td>\n",
       "      <td>0.838565</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.865741</td>\n",
       "      <td>0.982943</td>\n",
       "      <td>0.865741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.082830</td>\n",
       "      <td>0.813043</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.851936</td>\n",
       "      <td>0.982943</td>\n",
       "      <td>0.851936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.087885</td>\n",
       "      <td>0.850679</td>\n",
       "      <td>0.899522</td>\n",
       "      <td>0.874419</td>\n",
       "      <td>0.983810</td>\n",
       "      <td>0.874419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.087118</td>\n",
       "      <td>0.855204</td>\n",
       "      <td>0.904306</td>\n",
       "      <td>0.879070</td>\n",
       "      <td>0.984678</td>\n",
       "      <td>0.879070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.093219</td>\n",
       "      <td>0.852018</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.879630</td>\n",
       "      <td>0.984099</td>\n",
       "      <td>0.879630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.097454</td>\n",
       "      <td>0.843049</td>\n",
       "      <td>0.899522</td>\n",
       "      <td>0.870370</td>\n",
       "      <td>0.983521</td>\n",
       "      <td>0.870370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.098747</td>\n",
       "      <td>0.856502</td>\n",
       "      <td>0.913876</td>\n",
       "      <td>0.884259</td>\n",
       "      <td>0.984678</td>\n",
       "      <td>0.884259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.095253</td>\n",
       "      <td>0.776824</td>\n",
       "      <td>0.866029</td>\n",
       "      <td>0.819005</td>\n",
       "      <td>0.981787</td>\n",
       "      <td>0.819005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.089047</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.870813</td>\n",
       "      <td>0.840647</td>\n",
       "      <td>0.980052</td>\n",
       "      <td>0.840647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.093860</td>\n",
       "      <td>0.787500</td>\n",
       "      <td>0.904306</td>\n",
       "      <td>0.841871</td>\n",
       "      <td>0.978896</td>\n",
       "      <td>0.841871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.088758</td>\n",
       "      <td>0.844444</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.875576</td>\n",
       "      <td>0.982365</td>\n",
       "      <td>0.875576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.081585</td>\n",
       "      <td>0.864253</td>\n",
       "      <td>0.913876</td>\n",
       "      <td>0.888372</td>\n",
       "      <td>0.984389</td>\n",
       "      <td>0.888372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.096172</td>\n",
       "      <td>0.831111</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.861751</td>\n",
       "      <td>0.981787</td>\n",
       "      <td>0.861751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.092770</td>\n",
       "      <td>0.878505</td>\n",
       "      <td>0.899522</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.983521</td>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.095457</td>\n",
       "      <td>0.853211</td>\n",
       "      <td>0.889952</td>\n",
       "      <td>0.871194</td>\n",
       "      <td>0.980341</td>\n",
       "      <td>0.871194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.111580</td>\n",
       "      <td>0.848624</td>\n",
       "      <td>0.885167</td>\n",
       "      <td>0.866511</td>\n",
       "      <td>0.978317</td>\n",
       "      <td>0.866511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.106761</td>\n",
       "      <td>0.865741</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.982654</td>\n",
       "      <td>0.880000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.108982</td>\n",
       "      <td>0.816594</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.853881</td>\n",
       "      <td>0.981498</td>\n",
       "      <td>0.853881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.121644</td>\n",
       "      <td>0.840183</td>\n",
       "      <td>0.880383</td>\n",
       "      <td>0.859813</td>\n",
       "      <td>0.980341</td>\n",
       "      <td>0.859813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.133871</td>\n",
       "      <td>0.836364</td>\n",
       "      <td>0.880383</td>\n",
       "      <td>0.857809</td>\n",
       "      <td>0.979185</td>\n",
       "      <td>0.857809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.128457</td>\n",
       "      <td>0.837963</td>\n",
       "      <td>0.866029</td>\n",
       "      <td>0.851765</td>\n",
       "      <td>0.978607</td>\n",
       "      <td>0.851765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.124290</td>\n",
       "      <td>0.802632</td>\n",
       "      <td>0.875598</td>\n",
       "      <td>0.837529</td>\n",
       "      <td>0.977739</td>\n",
       "      <td>0.837529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.112941</td>\n",
       "      <td>0.845455</td>\n",
       "      <td>0.889952</td>\n",
       "      <td>0.867133</td>\n",
       "      <td>0.980052</td>\n",
       "      <td>0.867133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.101754</td>\n",
       "      <td>0.866359</td>\n",
       "      <td>0.899522</td>\n",
       "      <td>0.882629</td>\n",
       "      <td>0.983521</td>\n",
       "      <td>0.882629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.108544</td>\n",
       "      <td>0.825893</td>\n",
       "      <td>0.885167</td>\n",
       "      <td>0.854503</td>\n",
       "      <td>0.980630</td>\n",
       "      <td>0.854503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.105643</td>\n",
       "      <td>0.838565</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.865741</td>\n",
       "      <td>0.982076</td>\n",
       "      <td>0.865741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.028600</td>\n",
       "      <td>0.108680</td>\n",
       "      <td>0.834081</td>\n",
       "      <td>0.889952</td>\n",
       "      <td>0.861111</td>\n",
       "      <td>0.981498</td>\n",
       "      <td>0.861111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.028600</td>\n",
       "      <td>0.110700</td>\n",
       "      <td>0.834081</td>\n",
       "      <td>0.889952</td>\n",
       "      <td>0.861111</td>\n",
       "      <td>0.981498</td>\n",
       "      <td>0.861111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.028600</td>\n",
       "      <td>0.111784</td>\n",
       "      <td>0.830357</td>\n",
       "      <td>0.889952</td>\n",
       "      <td>0.859122</td>\n",
       "      <td>0.981787</td>\n",
       "      <td>0.859122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.028600</td>\n",
       "      <td>0.110794</td>\n",
       "      <td>0.818584</td>\n",
       "      <td>0.885167</td>\n",
       "      <td>0.850575</td>\n",
       "      <td>0.980919</td>\n",
       "      <td>0.850575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.028600</td>\n",
       "      <td>0.111603</td>\n",
       "      <td>0.810573</td>\n",
       "      <td>0.880383</td>\n",
       "      <td>0.844037</td>\n",
       "      <td>0.980052</td>\n",
       "      <td>0.844037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.028600</td>\n",
       "      <td>0.109745</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.889952</td>\n",
       "      <td>0.873239</td>\n",
       "      <td>0.982943</td>\n",
       "      <td>0.873239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.028600</td>\n",
       "      <td>0.112135</td>\n",
       "      <td>0.846512</td>\n",
       "      <td>0.870813</td>\n",
       "      <td>0.858491</td>\n",
       "      <td>0.982365</td>\n",
       "      <td>0.858491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.028600</td>\n",
       "      <td>0.109761</td>\n",
       "      <td>0.825893</td>\n",
       "      <td>0.885167</td>\n",
       "      <td>0.854503</td>\n",
       "      <td>0.980630</td>\n",
       "      <td>0.854503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.028600</td>\n",
       "      <td>0.112637</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.880383</td>\n",
       "      <td>0.849885</td>\n",
       "      <td>0.981787</td>\n",
       "      <td>0.849885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.028600</td>\n",
       "      <td>0.112193</td>\n",
       "      <td>0.857798</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.875878</td>\n",
       "      <td>0.983521</td>\n",
       "      <td>0.875878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.028600</td>\n",
       "      <td>0.111311</td>\n",
       "      <td>0.853211</td>\n",
       "      <td>0.889952</td>\n",
       "      <td>0.871194</td>\n",
       "      <td>0.981498</td>\n",
       "      <td>0.871194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.028600</td>\n",
       "      <td>0.120552</td>\n",
       "      <td>0.825112</td>\n",
       "      <td>0.880383</td>\n",
       "      <td>0.851852</td>\n",
       "      <td>0.979474</td>\n",
       "      <td>0.851852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>0.028600</td>\n",
       "      <td>0.107369</td>\n",
       "      <td>0.857798</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.875878</td>\n",
       "      <td>0.982654</td>\n",
       "      <td>0.875878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.028600</td>\n",
       "      <td>0.100287</td>\n",
       "      <td>0.849315</td>\n",
       "      <td>0.889952</td>\n",
       "      <td>0.869159</td>\n",
       "      <td>0.982943</td>\n",
       "      <td>0.869159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.028600</td>\n",
       "      <td>0.115598</td>\n",
       "      <td>0.809735</td>\n",
       "      <td>0.875598</td>\n",
       "      <td>0.841379</td>\n",
       "      <td>0.978896</td>\n",
       "      <td>0.841379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.028600</td>\n",
       "      <td>0.101610</td>\n",
       "      <td>0.844749</td>\n",
       "      <td>0.885167</td>\n",
       "      <td>0.864486</td>\n",
       "      <td>0.982943</td>\n",
       "      <td>0.864486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.028600</td>\n",
       "      <td>0.096747</td>\n",
       "      <td>0.834821</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.863741</td>\n",
       "      <td>0.982076</td>\n",
       "      <td>0.863741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.028600</td>\n",
       "      <td>0.098715</td>\n",
       "      <td>0.829596</td>\n",
       "      <td>0.885167</td>\n",
       "      <td>0.856481</td>\n",
       "      <td>0.980919</td>\n",
       "      <td>0.856481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.028600</td>\n",
       "      <td>0.097969</td>\n",
       "      <td>0.825112</td>\n",
       "      <td>0.880383</td>\n",
       "      <td>0.851852</td>\n",
       "      <td>0.981498</td>\n",
       "      <td>0.851852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.028600</td>\n",
       "      <td>0.100224</td>\n",
       "      <td>0.790393</td>\n",
       "      <td>0.866029</td>\n",
       "      <td>0.826484</td>\n",
       "      <td>0.979185</td>\n",
       "      <td>0.826484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.028600</td>\n",
       "      <td>0.101746</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.870813</td>\n",
       "      <td>0.827273</td>\n",
       "      <td>0.979763</td>\n",
       "      <td>0.827273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.028600</td>\n",
       "      <td>0.101916</td>\n",
       "      <td>0.796537</td>\n",
       "      <td>0.880383</td>\n",
       "      <td>0.836364</td>\n",
       "      <td>0.979474</td>\n",
       "      <td>0.836364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>0.028600</td>\n",
       "      <td>0.093717</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.880383</td>\n",
       "      <td>0.849885</td>\n",
       "      <td>0.981498</td>\n",
       "      <td>0.849885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>0.028600</td>\n",
       "      <td>0.096167</td>\n",
       "      <td>0.834081</td>\n",
       "      <td>0.889952</td>\n",
       "      <td>0.861111</td>\n",
       "      <td>0.981498</td>\n",
       "      <td>0.861111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>0.028600</td>\n",
       "      <td>0.098041</td>\n",
       "      <td>0.856502</td>\n",
       "      <td>0.913876</td>\n",
       "      <td>0.884259</td>\n",
       "      <td>0.981208</td>\n",
       "      <td>0.884259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.028600</td>\n",
       "      <td>0.095930</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>0.889952</td>\n",
       "      <td>0.851259</td>\n",
       "      <td>0.981498</td>\n",
       "      <td>0.851259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>0.028600</td>\n",
       "      <td>0.096949</td>\n",
       "      <td>0.832599</td>\n",
       "      <td>0.904306</td>\n",
       "      <td>0.866972</td>\n",
       "      <td>0.981787</td>\n",
       "      <td>0.866972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>0.028600</td>\n",
       "      <td>0.094181</td>\n",
       "      <td>0.831858</td>\n",
       "      <td>0.899522</td>\n",
       "      <td>0.864368</td>\n",
       "      <td>0.982076</td>\n",
       "      <td>0.864368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>0.028600</td>\n",
       "      <td>0.093326</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>0.899522</td>\n",
       "      <td>0.868360</td>\n",
       "      <td>0.983232</td>\n",
       "      <td>0.868360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>0.028600</td>\n",
       "      <td>0.093426</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.885781</td>\n",
       "      <td>0.983810</td>\n",
       "      <td>0.885781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>0.028600</td>\n",
       "      <td>0.096238</td>\n",
       "      <td>0.856481</td>\n",
       "      <td>0.885167</td>\n",
       "      <td>0.870588</td>\n",
       "      <td>0.983232</td>\n",
       "      <td>0.870588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.028600</td>\n",
       "      <td>0.097320</td>\n",
       "      <td>0.865116</td>\n",
       "      <td>0.889952</td>\n",
       "      <td>0.877358</td>\n",
       "      <td>0.983810</td>\n",
       "      <td>0.877358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>0.028600</td>\n",
       "      <td>0.097672</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.885167</td>\n",
       "      <td>0.872642</td>\n",
       "      <td>0.983810</td>\n",
       "      <td>0.872642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>0.028600</td>\n",
       "      <td>0.096787</td>\n",
       "      <td>0.828054</td>\n",
       "      <td>0.875598</td>\n",
       "      <td>0.851163</td>\n",
       "      <td>0.982365</td>\n",
       "      <td>0.851163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>0.028600</td>\n",
       "      <td>0.092524</td>\n",
       "      <td>0.819005</td>\n",
       "      <td>0.866029</td>\n",
       "      <td>0.841860</td>\n",
       "      <td>0.983232</td>\n",
       "      <td>0.841860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>0.028600</td>\n",
       "      <td>0.089843</td>\n",
       "      <td>0.836364</td>\n",
       "      <td>0.880383</td>\n",
       "      <td>0.857809</td>\n",
       "      <td>0.983521</td>\n",
       "      <td>0.857809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.028600</td>\n",
       "      <td>0.094979</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.980341</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>0.028600</td>\n",
       "      <td>0.097542</td>\n",
       "      <td>0.754237</td>\n",
       "      <td>0.851675</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.980630</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0.100476</td>\n",
       "      <td>0.780172</td>\n",
       "      <td>0.866029</td>\n",
       "      <td>0.820862</td>\n",
       "      <td>0.982365</td>\n",
       "      <td>0.820862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0.097270</td>\n",
       "      <td>0.795652</td>\n",
       "      <td>0.875598</td>\n",
       "      <td>0.833713</td>\n",
       "      <td>0.983232</td>\n",
       "      <td>0.833713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0.096864</td>\n",
       "      <td>0.807860</td>\n",
       "      <td>0.885167</td>\n",
       "      <td>0.844749</td>\n",
       "      <td>0.983232</td>\n",
       "      <td>0.844749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0.093414</td>\n",
       "      <td>0.831111</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.861751</td>\n",
       "      <td>0.983810</td>\n",
       "      <td>0.861751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0.093323</td>\n",
       "      <td>0.850679</td>\n",
       "      <td>0.899522</td>\n",
       "      <td>0.874419</td>\n",
       "      <td>0.984967</td>\n",
       "      <td>0.874419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0.092707</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.904306</td>\n",
       "      <td>0.887324</td>\n",
       "      <td>0.985545</td>\n",
       "      <td>0.887324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0.092866</td>\n",
       "      <td>0.879070</td>\n",
       "      <td>0.904306</td>\n",
       "      <td>0.891509</td>\n",
       "      <td>0.986412</td>\n",
       "      <td>0.891509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0.092574</td>\n",
       "      <td>0.879070</td>\n",
       "      <td>0.904306</td>\n",
       "      <td>0.891509</td>\n",
       "      <td>0.986123</td>\n",
       "      <td>0.891509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0.090892</td>\n",
       "      <td>0.879070</td>\n",
       "      <td>0.904306</td>\n",
       "      <td>0.891509</td>\n",
       "      <td>0.986123</td>\n",
       "      <td>0.891509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0.089569</td>\n",
       "      <td>0.879070</td>\n",
       "      <td>0.904306</td>\n",
       "      <td>0.891509</td>\n",
       "      <td>0.986412</td>\n",
       "      <td>0.891509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0.090835</td>\n",
       "      <td>0.879070</td>\n",
       "      <td>0.904306</td>\n",
       "      <td>0.891509</td>\n",
       "      <td>0.986412</td>\n",
       "      <td>0.891509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0.090419</td>\n",
       "      <td>0.887850</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.898345</td>\n",
       "      <td>0.986701</td>\n",
       "      <td>0.898345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0.090313</td>\n",
       "      <td>0.887850</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.898345</td>\n",
       "      <td>0.986412</td>\n",
       "      <td>0.898345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0.090700</td>\n",
       "      <td>0.887850</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.898345</td>\n",
       "      <td>0.986412</td>\n",
       "      <td>0.898345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0.091065</td>\n",
       "      <td>0.887850</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.898345</td>\n",
       "      <td>0.986412</td>\n",
       "      <td>0.898345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0.090921</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.896226</td>\n",
       "      <td>0.986123</td>\n",
       "      <td>0.896226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0.090902</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.896226</td>\n",
       "      <td>0.986412</td>\n",
       "      <td>0.896226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0.090799</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.896226</td>\n",
       "      <td>0.986412</td>\n",
       "      <td>0.896226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0.090992</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.896226</td>\n",
       "      <td>0.986412</td>\n",
       "      <td>0.896226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0.091033</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.896226</td>\n",
       "      <td>0.986412</td>\n",
       "      <td>0.896226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0.090961</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.896226</td>\n",
       "      <td>0.986412</td>\n",
       "      <td>0.896226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0.090990</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.904306</td>\n",
       "      <td>0.889412</td>\n",
       "      <td>0.986123</td>\n",
       "      <td>0.889412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0.091064</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.904306</td>\n",
       "      <td>0.889412</td>\n",
       "      <td>0.986123</td>\n",
       "      <td>0.889412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0.091056</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.904306</td>\n",
       "      <td>0.889412</td>\n",
       "      <td>0.986123</td>\n",
       "      <td>0.889412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "Saving model checkpoint to ./results/checkpoint-500\n",
      "Configuration saved in ./results/checkpoint-500/config.json\n",
      "Model weights saved in ./results/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-500/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "Saving model checkpoint to ./results/checkpoint-1000\n",
      "Configuration saved in ./results/checkpoint-1000/config.json\n",
      "Model weights saved in ./results/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-1000/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1300, training_loss=0.012114588755827684, metrics={'train_runtime': 368.7926, 'train_samples_per_second': 21.15, 'train_steps_per_second': 3.525, 'total_flos': 3609921712205052.0, 'train_loss': 0.012114588755827684, 'epoch': 100.0})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.09105609357357025,\n",
       " 'eval_overall_precision': 0.875,\n",
       " 'eval_overall_recall': 0.9043062200956937,\n",
       " 'eval_overall_f1': 0.8894117647058823,\n",
       " 'eval_overall_accuracy': 0.9861231569817867,\n",
       " 'eval_SENTENCE_f1': 0.8894117647058823,\n",
       " 'eval_runtime': 0.3147,\n",
       " 'eval_samples_per_second': 63.556,\n",
       " 'eval_steps_per_second': 12.711,\n",
       " 'epoch': 100.0}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./NEWS_Sentence_2/config.json\n",
      "Model weights saved in ./NEWS_Sentence_2/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "model.save_pretrained('./NEWS_Sentence_2/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in ./NEWS_TOK_2/tokenizer_config.json\n",
      "Special tokens file saved in ./NEWS_TOK_2/special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./NEWS_TOK_2/tokenizer_config.json',\n",
       " './NEWS_TOK_2/special_tokens_map.json',\n",
       " './NEWS_TOK_2/vocab.txt',\n",
       " './NEWS_TOK_2/added_tokens.json',\n",
       " './NEWS_TOK_2/tokenizer.json')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_pretrained('./NEWS_TOK_2/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
